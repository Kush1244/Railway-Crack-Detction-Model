{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXRLN4Uql0Ig",
        "outputId": "9ad2890e-c6cc-457f-a50b-3ad21478a0d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5153 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Step 2: Create Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Railway-Track-Surface-Faults-Dataset'\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MAKoh7pl0Ig",
        "outputId": "7dbdc10a-c4b6-4c42-e2ef-4df71a333dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 3: Load Pre-trained VGG16 Model\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "vgg_base.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Add Custom Classifier\n",
        "x = Flatten()(vgg_base.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=vgg_base.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "-LYE5U1JylRF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rDha_vxnyo04"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Z4muHQy3Uq",
        "outputId": "806444d4-9eca-4319-9e89-3ddd33b5ef3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6422784   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21139271 (80.64 MB)\n",
            "Trainable params: 6424583 (24.51 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnbiTUJ_yr-2",
        "outputId": "071274b1-7831-447b-e77c-dd648c215126"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "161/161 [==============================] - 1746s 11s/step - loss: 1.5897 - accuracy: 0.6038\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 99s 616ms/step - loss: 0.9046 - accuracy: 0.6413\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 101s 629ms/step - loss: 0.8144 - accuracy: 0.6922\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 99s 612ms/step - loss: 0.7835 - accuracy: 0.7032\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 99s 612ms/step - loss: 0.7631 - accuracy: 0.7112\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 100s 621ms/step - loss: 0.7455 - accuracy: 0.7137\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 100s 620ms/step - loss: 0.7427 - accuracy: 0.7133\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 100s 619ms/step - loss: 0.7139 - accuracy: 0.7282\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 99s 615ms/step - loss: 0.6971 - accuracy: 0.7270\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 100s 623ms/step - loss: 0.7066 - accuracy: 0.7225\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7998de58fb20>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Predict Class for New Images\n",
        "# Load your test images and preprocess them similarly to the training images.\n",
        "# Then use model.predict() to get the predicted probabilities or classes.\n",
        "\n",
        "# Step 8: Class Name Mapping\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "# Example usage of model.predict()\n",
        "# test_image = load_and_preprocess_test_image('test_image.jpg')\n",
        "# predictions = model.predict(test_image)\n",
        "# predicted_class_index = tf.argmax(predictions, axis=1)\n",
        "# predicted_class_name = class_names[predicted_class_index]\n"
      ],
      "metadata": {
        "id": "-oC5TLYpytyJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Railway-Track-Surface-Faults.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubJRp5Jkyv7X",
        "outputId": "481eb293-7f59-4ce7-db63-881991b6ec2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "  img = load_img(image_path, target_size=(224, 224))\n",
        "  img_array = img_to_array(img)\n",
        "  img_array /= 255.0\n",
        "  return np.expand_dims(img_array, axis=0)"
      ],
      "metadata": {
        "id": "XRe_6bL0LOqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}